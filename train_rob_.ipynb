{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:09.672735Z",
     "start_time": "2025-08-12T13:14:04.385153Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from src.trainer import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "from src.loss import YoloLoss, YoloLossV1\n",
    "from src.dataset_rob import DroneDetection\n",
    "from src.model import YoloTiny, count_parameters\n",
    "from src.utils import display_stats, calculate_map, display_train_eval_batch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:09.678373Z",
     "start_time": "2025-08-12T13:14:09.675871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_PATH = \"/Volumes/Lexar/ML DATA/Detection Dataset/Robflow\"\n",
    "OPTIM_PATH = \"models/yolo_optimizer_rob.pth\"\n",
    "MODEL_WEIGHTS_PATH = \"models/yolo_model_rob.pth\"\n",
    "STATS_PATH = \"stats/yoloy_model_stats_rob.npz\"\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ],
   "id": "b60cdf0b1915f36e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:09.737124Z",
     "start_time": "2025-08-12T13:14:09.734961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training parameters\n",
    "IM_SIZE = 448\n",
    "threshold = 0.5\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "FACTOR = 0.5\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOPPING = PATIENCE * 2"
   ],
   "id": "5b751d4a574f8a7c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:09.745143Z",
     "start_time": "2025-08-12T13:14:09.743115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters\n",
    "f = 16\n",
    "n_reg = 5\n",
    "p_box = 2\n",
    "d_fc = 496\n",
    "n_classes = 2\n",
    "cell_size = 7\n",
    "out_channels = (cell_size * cell_size) * (n_classes + n_reg * p_box)"
   ],
   "id": "9ed492a8c4544f00",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:09.830758Z",
     "start_time": "2025-08-12T13:14:09.750599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = YoloTiny(in_channels=3, out_channels=out_channels, f = f, d_fc = d_fc, dropt=0.2, im_size=IM_SIZE)\n",
    "print(f\"Paramètres : {count_parameters(model):,}\")"
   ],
   "id": "b80ad17d010542ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètres : 25,573,132\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:13.416427Z",
     "start_time": "2025-08-12T13:14:09.836960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(model=model, threshold=threshold, batch_size=BATCH_SIZE, device=device, B=p_box, C=n_classes, S=cell_size)\n",
    "criterion = YoloLoss(n_cell=cell_size, n_box=p_box, n_classes=n_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=FACTOR, patience=PATIENCE,\n",
    ")\n",
    "RobDroneDetectionDataset = DroneDetection(data_path=DATA_PATH, i_size=IM_SIZE, cell_size=cell_size, n_box=p_box, n_classes=n_classes)\n",
    "train_loader, valid_loader = RobDroneDetectionDataset.load_data(batch_size = BATCH_SIZE, n_workers=NUM_WORKERS)"
   ],
   "id": "7ddad929c0213d11",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T13:14:13.569947Z",
     "start_time": "2025-08-12T13:14:13.430123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lists to store the training and validation statistics\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_map = []\n",
    "epochs_mAP = 0\n",
    "epochs_mAP_50 = 0\n",
    "epochs_mAP_per_class = 0\n",
    "best_val_loss = float('inf')\n",
    "current_patience_step = 0\n",
    "test_visual_batch = next(iter(valid_loader))"
   ],
   "id": "ab6194df4c091cf8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:12:54.047437Z",
     "start_time": "2025-08-12T13:14:13.581433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pbar = tqdm(range(EPOCHS), desc=\"Epochs: \")\n",
    "# Training loop\n",
    "for ep in pbar:\n",
    "    # Set model to training mode and reset statistics at the start of each epoch\n",
    "    model.train()\n",
    "    trainer.init_params()\n",
    "    for data_train in train_loader:\n",
    "        # Perform training steps\n",
    "        trainer.train_step(data_train, criterion, optimizer)\n",
    "    \n",
    "    epochs_train_loss = trainer.train_loss / len(train_loader)\n",
    "    # Store training stats for this epoch\n",
    "    train_losses.append(epochs_train_loss)\n",
    "    is_compute_map = (ep + 1)%5 == 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        if is_compute_map:\n",
    "            images, target = test_visual_batch\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "            predictions = model(images)\n",
    "            display_train_eval_batch(images, predictions, target, threshold=threshold, im_size=IM_SIZE)\n",
    "\n",
    "        for eval_batch_idx, data_valid in enumerate(valid_loader):\n",
    "            trainer.val_step(data_valid, criterion, is_compute_map)\n",
    "    epochs_val_loss = trainer.val_loss / len(valid_loader)\n",
    "    scheduler.step(epochs_val_loss)\n",
    "    if is_compute_map:\n",
    "        try:\n",
    "            pred_boxes = torch.cat(trainer.pred_boxes, dim=0)\n",
    "            true_boxes = torch.cat(trainer.true_boxes, dim=0)\n",
    "        except RuntimeError as e:\n",
    "            # If concatenation fails due to shape mismatch, handle accordingly\n",
    "            print(f\"Shape mismatch error: {e}\")\n",
    "            print(\"Tensor shapes in pred_boxes:\", [t.shape for t in trainer.pred_boxes])\n",
    "            print(\"Tensor shapes in true_boxes:\", [t.shape for t in trainer.true_boxes])\n",
    "            # You might need to pad or reshape tensors here\n",
    "            pred_boxes = torch.stack(trainer.pred_boxes, dim=0)\n",
    "            true_boxes = torch.stack(trainer.true_boxes, dim=0)\n",
    "            \n",
    "        results = calculate_map(pred_boxes, true_boxes, n_cell=cell_size, n_classes=n_classes, n_box=p_box)\n",
    "        epochs_mAP = results['map'].item()\n",
    "        epochs_mAP_50 = results['map_50'].item()\n",
    "        epochs_mAP_per_class = results['map_per_class']\n",
    "        valid_map.append(epochs_mAP)\n",
    "        \n",
    "    valid_losses.append(epochs_val_loss)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        'train_loss': f'{epochs_train_loss:.4f}',\n",
    "        'val_loss': f'{epochs_val_loss:.4f}',\n",
    "        'best_val_loss': f'{best_val_loss:.4f}',\n",
    "        'val_AP': f'{epochs_mAP:.4f}',\n",
    "        'val_mAP@50': f'{epochs_mAP_50:.4f}',\n",
    "        'val_mAP@perclass': f'{epochs_mAP_per_class}'\n",
    "    })\n",
    "    \n",
    "    if epochs_val_loss < best_val_loss:\n",
    "        best_val_loss = epochs_val_loss\n",
    "        current_patience_step = 0\n",
    "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
    "    else:\n",
    "        current_patience_step += 1\n",
    "        if current_patience_step >= EARLY_STOPPING:\n",
    "            print(\"Early stopping triggered\")\n",
    "            model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))\n",
    "            break\n",
    "            \n",
    "print(\"Training completed.\")"
   ],
   "id": "ec17a61684588f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   8%|▊         | 4/50 [58:37<11:14:12, 879.41s/it, train_loss=202.5970, val_loss=148.8749, best_val_loss=169.2296, val_AP=0.0000, val_mAP@50=0.0000, val_mAP@perclass=0] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.05 GB, other allocations: 863.70 MB, max allowed: 9.07 GB). Tried to allocate 392.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m trainer\u001B[38;5;241m.\u001B[39minit_params()\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data_train \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# Perform training steps\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m epochs_train_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mtrain_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Store training stats for this epoch\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/DroneObjDetection/src/trainer.py:28\u001B[0m, in \u001B[0;36mTrainer.train_step\u001B[0;34m(self, data, criterion, optimizer)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     27\u001B[0m X, y \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice), data[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 28\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Compute loss\u001B[39;00m\n\u001B[1;32m     30\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(y_pred, y)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/PycharmProjects/DroneObjDetection/src/model.py:72\u001B[0m, in \u001B[0;36mYoloTiny.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     68\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;124;03m    :param x: Magnitude d'un patch du spectogramme\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :return: la probabilité de chaque classe\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/container.py:240\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 240\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/modules/activation.py:828\u001B[0m, in \u001B[0;36mLeakyReLU.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 828\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleaky_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnegative_slope\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/image_env/lib/python3.9/site-packages/torch/nn/functional.py:1902\u001B[0m, in \u001B[0;36mleaky_relu\u001B[0;34m(input, negative_slope, inplace)\u001B[0m\n\u001B[1;32m   1900\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mleaky_relu_(\u001B[38;5;28minput\u001B[39m, negative_slope)\n\u001B[1;32m   1901\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1902\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mleaky_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnegative_slope\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1903\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 8.05 GB, other allocations: 863.70 MB, max allowed: 9.07 GB). Tried to allocate 392.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the trained model parameters\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
    "torch.save(optimizer.state_dict(), OPTIM_PATH)\n",
    "# Save training and validation statistics to a file\n",
    "np.savez(STATS_PATH, train_losses=np.array(train_losses), valid_losses=np.array(valid_losses), allow_pickle=True)"
   ],
   "id": "2e263a70bf0aa70b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load model training statistics (accuracy and loss)\n",
    "training_stats  = np.load(STATS_PATH)\n",
    "# Display the training statistics\n",
    "display_stats(training_stats)"
   ],
   "id": "89711a22b777d149",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(valid_map)\n",
    "plt.title('Validation mAp')\n",
    "plt.show()"
   ],
   "id": "3311e7c325ae0b8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    trainer.init_params()\n",
    "    model.eval()\n",
    "    for eval_batch_idx, data_valid in enumerate(valid_loader):\n",
    "        trainer.val_step(data_valid, criterion, True)\n",
    "    epochs_val_loss = trainer.val_loss / len(valid_loader)\n",
    "    try:\n",
    "        pred_boxes = torch.cat(trainer.pred_boxes, dim=0)\n",
    "        true_boxes = torch.cat(trainer.true_boxes, dim=0)\n",
    "    except RuntimeError as e:\n",
    "        # If concatenation fails due to shape mismatch, handle accordingly\n",
    "        print(f\"Shape mismatch error: {e}\")\n",
    "        print(\"Tensor shapes in pred_boxes:\", [t.shape for t in trainer.pred_boxes])\n",
    "        print(\"Tensor shapes in true_boxes:\", [t.shape for t in trainer.true_boxes])\n",
    "        # You might need to pad or reshape tensors here\n",
    "        pred_boxes = torch.stack(trainer.pred_boxes, dim=0)\n",
    "        true_boxes = torch.stack(trainer.true_boxes, dim=0)\n",
    "        \n",
    "    results = calculate_map(pred_boxes, true_boxes, n_cell=cell_size, n_classes=n_classes, n_box=p_box)\n",
    "    epochs_mAP = results['map'].item()\n",
    "    epochs_mAP_50 = results['map_50'].item()\n",
    "    epochs_mAP_per_class = results['map_per_class']\n",
    "# Print evaluation results\n",
    "print(f'\\nTest set: Average loss: {epochs_val_loss:.4f}, mAp: {epochs_mAP}, mAp@50: {epochs_mAP_50}, mAp/class: {epochs_mAP_per_class}\\n')"
   ],
   "id": "d83bdff72b7f056d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
